{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Neural Network using NN module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<img src=\"mlp_mnist.png\" width=600px>\n",
    "\n",
    "> **Exercise:** Create a network with 784 input units, a hidden layer with 128 units and a ReLU activation, then a hidden layer with 64 units and a ReLU activation, and finally an output layer with a softmax activation as shown above. You can use a ReLU activation with the `nn.ReLU` module or `F.relu` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run this cell\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "#transforms.Compose just clubs all the transforms provided to it\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5,), (0.5,)),\n",
    "                              ])\n",
    "# Download and load the training data\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        #the self.hidden1 = nn.Linear(784, 256) defines a hidden,#fully connected linear layer, \n",
    "        #which takes input x of shape (batch_size, 784), where batch size is the number of inputs (each of size 784) which are passed to the network at once (as a single tensor), \n",
    "        #and transforms it by the linear equation y = x*W^T + b into a tensor y of shape (batch_size, 128)\n",
    "        self.hidden1 = nn.Linear(784, 128)\n",
    "\n",
    "        self.hidden2 = nn.Linear(128, 64)\n",
    "\n",
    "        self.output = nn.Linear(64,10)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        \n",
    "        X = self.hidden1(X)\n",
    "        X = F.relu(X)\n",
    "        X = self.hidden2(X)\n",
    "        X = F.relu(X)\n",
    "        X = self.output(X)\n",
    "        X = F.softmax(X)\n",
    "\n",
    "        return X\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (hidden1): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (hidden2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (output): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Network()\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0069, -0.0006, -0.0166,  ...,  0.0187,  0.0189, -0.0092],\n",
      "        [ 0.0279,  0.0152, -0.0212,  ...,  0.0047,  0.0295, -0.0248],\n",
      "        [ 0.0162, -0.0287, -0.0052,  ..., -0.0256, -0.0185, -0.0303],\n",
      "        ...,\n",
      "        [-0.0104, -0.0317,  0.0036,  ...,  0.0058,  0.0283,  0.0138],\n",
      "        [ 0.0120, -0.0341, -0.0246,  ...,  0.0203, -0.0079, -0.0135],\n",
      "        [-0.0266, -0.0213, -0.0282,  ...,  0.0231, -0.0002,  0.0044]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0797, -0.0064,  0.0707,  ...,  0.0697,  0.0583, -0.0643],\n",
      "        [ 0.0299,  0.0795, -0.0847,  ...,  0.0132,  0.0823,  0.0565],\n",
      "        [ 0.0290, -0.0865,  0.0042,  ...,  0.0547, -0.0879,  0.0429],\n",
      "        ...,\n",
      "        [-0.0776,  0.0548,  0.0056,  ...,  0.0280,  0.0660, -0.0771],\n",
      "        [ 0.0796, -0.0668,  0.0074,  ..., -0.0462,  0.0129,  0.0272],\n",
      "        [ 0.0526,  0.0472,  0.0350,  ...,  0.0799,  0.0473,  0.0637]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(model.hidden1.weight)\n",
    "print(model.hidden2.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Setting biases to all zeros\n",
    "model.hidden1.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get some data\n",
    "dataiter = iter(trainloader)\n",
    "images, label = dataiter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "import helper\n",
    "\n",
    "images.resize_(64, 1, 784)\n",
    "img_idx = 3\n",
    "ps = model.forward(images[img_idx,:])\n",
    "\n",
    "img = images[img_idx]\n",
    "helper.view_classify(img.view(1,28,28), ps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using nn.Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=784, out_features=128, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=64, out_features=10, bias=True)\n",
      "  (5): Softmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters for network\n",
    "input_size = 784\n",
    "hidden_sizes = [128, 64]\n",
    "output_size = 10\n",
    "\n",
    "# Build a feed-forward network\n",
    "\n",
    "model = nn.Sequential(nn.Linear(input_size, hidden_sizes[0]),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(hidden_sizes[1], output_size),\n",
    "                     nn.Softmax(dim=1))\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Forward pass through the network and display output\n",
    "\n",
    "images, label = next(iter(trainloader))\n",
    "images.resize_(images.shape[0], 1, 784)\n",
    "ps = model.forward(images[0, :])\n",
    "helper.view_classify(images[3].view(1,28,28), ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=784, out_features=128, bias=True)\n"
     ]
    }
   ],
   "source": [
    "print(model[0])\n",
    "#model[0].weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also pass in an `OrderedDict` to name the individual layers and operations, instead of using incremental integers. Note that dictionary keys must be unique, so _each operation must have a different name_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (relu1): ReLU()\n",
       "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (relu2): ReLU()\n",
       "  (output): Linear(in_features=64, out_features=10, bias=True)\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "model = nn.Sequential(OrderedDict([\n",
    "                      ('fc1', nn.Linear(input_size, hidden_sizes[0])),\n",
    "                      ('relu1', nn.ReLU()),\n",
    "                      ('fc2', nn.Linear(hidden_sizes[0], hidden_sizes[1])),\n",
    "                      ('relu2', nn.ReLU()),\n",
    "                      ('output', nn.Linear(hidden_sizes[1], output_size)),\n",
    "                      ('softmax', nn.Softmax(dim=1))]))\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3019, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Get our data\n",
    "images, labels = next(iter(trainloader))\n",
    "# Flatten images\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "# Forward pass, get our logits\n",
    "logits = model(images)\n",
    "\n",
    "# Calculate the loss with the logits and the labesl\n",
    "loss = criterion(logits, labels)\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=784, out_features=128, bias=True)\n",
      "Linear(in_features=784, out_features=128, bias=True)\n"
     ]
    }
   ],
   "source": [
    "print(model[0])\n",
    "print(model.fc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "tensor(2.3159, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(OrderedDict([\n",
    "                      ('fc1', nn.Linear(input_size, hidden_sizes[0])),\n",
    "                      ('relu1', nn.ReLU()),\n",
    "                      ('fc2', nn.Linear(hidden_sizes[0], hidden_sizes[1])),\n",
    "                      ('relu2', nn.ReLU()),\n",
    "                      ('output', nn.Linear(hidden_sizes[1], output_size)),\n",
    "                      ('softmax', nn.LogSoftmax(dim=1))]))\n",
    "\n",
    "# Loss\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# Data\n",
    "images, labels = next(iter(trainloader))\n",
    "\n",
    "print(images.shape)\n",
    "\n",
    "# Flatten image\n",
    "images = images.view(images.shape[0], -1)\n",
    "print(images.shape)\n",
    "\n",
    "logits = model(images)\n",
    "\n",
    "loss = criterion(logits, labels)\n",
    "\n",
    "print(loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autograd ~ Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backward pass: \n",
      " None\n",
      "After backward pass: \n",
      " tensor([[-2.5711e-03, -2.5711e-03, -2.5711e-03,  ..., -2.5711e-03,\n",
      "         -2.5711e-03, -2.5711e-03],\n",
      "        [ 1.6251e-03,  1.6251e-03,  1.6251e-03,  ...,  1.6251e-03,\n",
      "          1.6251e-03,  1.6251e-03],\n",
      "        [ 5.6753e-04,  5.6753e-04,  5.6753e-04,  ...,  5.6753e-04,\n",
      "          5.6753e-04,  5.6753e-04],\n",
      "        ...,\n",
      "        [ 9.5209e-04,  9.5209e-04,  9.5209e-04,  ...,  9.5209e-04,\n",
      "          9.5209e-04,  9.5209e-04],\n",
      "        [-5.9242e-04, -5.9242e-04, -5.9242e-04,  ..., -5.9242e-04,\n",
      "         -5.9242e-04, -5.9242e-04],\n",
      "        [-5.7647e-06, -5.7647e-06, -5.7647e-06,  ..., -5.7648e-06,\n",
      "         -5.7648e-06, -5.7648e-06]])\n"
     ]
    }
   ],
   "source": [
    "print('Before backward pass: \\n', model[0].weight.grad)\n",
    "\n",
    "#After the backward, it calculates gradient for the weights\n",
    "loss.backward()\n",
    "print('After backward pass: \\n', model[0].weight.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider just one learning step before looping through all the data. The general process with PyTorch:\n",
    "\n",
    "* Make a forward pass through the network\n",
    "* Use the network output to calculate the loss\n",
    "* Perform a backward pass through the network with loss.backward() to calculate the gradients\n",
    "* Take a step with the optimizer to update the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial weights -  Parameter containing:\n",
      "tensor([[-0.0345,  0.0161,  0.0086,  ..., -0.0309, -0.0210, -0.0287],\n",
      "        [-0.0070,  0.0292, -0.0245,  ..., -0.0235, -0.0183,  0.0231],\n",
      "        [-0.0159, -0.0251,  0.0303,  ..., -0.0214,  0.0029,  0.0251],\n",
      "        ...,\n",
      "        [-0.0331,  0.0344,  0.0004,  ..., -0.0283, -0.0031,  0.0141],\n",
      "        [-0.0144, -0.0306, -0.0023,  ...,  0.0085,  0.0204,  0.0206],\n",
      "        [-0.0040, -0.0130,  0.0127,  ..., -0.0104,  0.0085,  0.0309]],\n",
      "       requires_grad=True)\n",
      "Gradient - tensor([[-3.5890e-03, -3.5890e-03, -3.5890e-03,  ..., -3.5890e-03,\n",
      "         -3.5890e-03, -3.5890e-03],\n",
      "        [-9.5139e-04, -9.5139e-04, -9.5139e-04,  ..., -9.5139e-04,\n",
      "         -9.5139e-04, -9.5139e-04],\n",
      "        [-1.4448e-03, -1.4448e-03, -1.4448e-03,  ..., -1.4448e-03,\n",
      "         -1.4448e-03, -1.4448e-03],\n",
      "        ...,\n",
      "        [ 2.2526e-06,  2.2526e-06,  2.2526e-06,  ...,  2.2526e-06,\n",
      "          2.2526e-06,  2.2526e-06],\n",
      "        [-1.8396e-03, -1.8396e-03, -1.8396e-03,  ..., -1.8396e-03,\n",
      "         -1.8396e-03, -1.8396e-03],\n",
      "        [-1.6600e-03, -1.6600e-03, -1.6600e-03,  ..., -1.6600e-03,\n",
      "         -1.6600e-03, -1.6600e-03]])\n"
     ]
    }
   ],
   "source": [
    "print('Initial weights - ', model[0].weight)\n",
    "\n",
    "images, label = next(iter(trainloader))\n",
    "images.resize_(64, 784)\n",
    "\n",
    "# Clear the gradients! PyTorch accumulates them\n",
    "optimizer.zero_grad()\n",
    "\n",
    "#Forward pass, then backward pass, then update weights\n",
    "output = model.forward(images)\n",
    "loss = criterion(output, labels)\n",
    "loss.backward()\n",
    "\n",
    "print('Gradient -', model[0].weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated weights ~ Parameter containing:\n",
      "tensor([[-0.0341,  0.0165,  0.0089,  ..., -0.0305, -0.0206, -0.0284],\n",
      "        [-0.0069,  0.0293, -0.0244,  ..., -0.0234, -0.0182,  0.0232],\n",
      "        [-0.0157, -0.0249,  0.0304,  ..., -0.0212,  0.0030,  0.0253],\n",
      "        ...,\n",
      "        [-0.0331,  0.0344,  0.0004,  ..., -0.0283, -0.0031,  0.0141],\n",
      "        [-0.0143, -0.0304, -0.0021,  ...,  0.0087,  0.0205,  0.0207],\n",
      "        [-0.0039, -0.0128,  0.0129,  ..., -0.0103,  0.0086,  0.0311]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Take an update step and few the new weights\n",
    "optimizer.step()\n",
    "print('Updated weights ~', model[0].weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:  1.9322911086621315\n",
      "Training loss:  0.8627794772577184\n",
      "Training loss:  0.5217400757806387\n",
      "Training loss:  0.4238052751019057\n",
      "Training loss:  0.37798984328122026\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(OrderedDict([\n",
    "                      ('fc1', nn.Linear(784,128)),\n",
    "                      ('relu1', nn.ReLU()),\n",
    "                      ('fc2', nn.Linear(128, 64)),\n",
    "                      ('relu2', nn.ReLU()),\n",
    "                      ('output', nn.Linear(64, 10)),\n",
    "                      ('softmax', nn.LogSoftmax(dim=1))]))\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.003)\n",
    "\n",
    "\n",
    "epochs = 5\n",
    "\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    \n",
    "    for images, labels in trainloader:\n",
    "        #Flatten MNIST images onto a 784 long vector\n",
    "        images = images.view(images.shape[0], -1)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #TRAINING\n",
    "        output = model.forward(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    else:\n",
    "        print('Training loss: ', running_loss / len(trainloader))    \n",
    "   \n",
    "    \n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import helper\n",
    "\n",
    "images,label = next(iter(trainloader))\n",
    "\n",
    "img = images[0].view(1, 784)\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model.forward(img)\n",
    "\n",
    "#output\n",
    "\n",
    "ps = F.softmax(logits, dim = 1)\n",
    "helper.view_classify(img.view(1,28,28), ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
