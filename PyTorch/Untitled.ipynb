{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Neural Network using NN module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<img src=\"mlp_mnist.png\" width=600px>\n",
    "\n",
    "> **Exercise:** Create a network with 784 input units, a hidden layer with 128 units and a ReLU activation, then a hidden layer with 64 units and a ReLU activation, and finally an output layer with a softmax activation as shown above. You can use a ReLU activation with the `nn.ReLU` module or `F.relu` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run this cell\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5,), (0.5,)),\n",
    "                              ])\n",
    "# Download and load the training data\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Network(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden1 = nn.Linear(784, 128)\n",
    "\n",
    "        self.hidden2 = nn.Linear(128, 64)\n",
    "\n",
    "        self.output = nn.Linear(64,10)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        \n",
    "        X = self.hidden1(X)\n",
    "        X = F.relu(X)\n",
    "        X = self.hidden2(X)\n",
    "        X = F.relu(X)\n",
    "        X = self.output(X)\n",
    "        X = F.softmax(X)\n",
    "\n",
    "        return X\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (hidden1): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (hidden2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (output): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Network()\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0265, -0.0175, -0.0278,  ..., -0.0353,  0.0298,  0.0125],\n",
      "        [ 0.0256,  0.0022,  0.0178,  ..., -0.0098, -0.0182, -0.0274],\n",
      "        [ 0.0265,  0.0114,  0.0185,  ...,  0.0249, -0.0201, -0.0006],\n",
      "        ...,\n",
      "        [-0.0324,  0.0003,  0.0139,  ..., -0.0322,  0.0152, -0.0293],\n",
      "        [-0.0139,  0.0123, -0.0198,  ...,  0.0335, -0.0325, -0.0240],\n",
      "        [ 0.0130, -0.0283, -0.0228,  ..., -0.0283,  0.0350, -0.0227]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0356,  0.0216, -0.0579,  ..., -0.0698,  0.0803, -0.0539],\n",
      "        [ 0.0516, -0.0146, -0.0704,  ...,  0.0606, -0.0253,  0.0314],\n",
      "        [-0.0679,  0.0028,  0.0259,  ...,  0.0125,  0.0351, -0.0295],\n",
      "        ...,\n",
      "        [ 0.0589,  0.0637,  0.0110,  ...,  0.0453, -0.0356,  0.0284],\n",
      "        [-0.0780,  0.0129,  0.0036,  ...,  0.0648, -0.0443,  0.0215],\n",
      "        [ 0.0872, -0.0481, -0.0208,  ...,  0.0482, -0.0794, -0.0365]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(model.hidden1.weight)\n",
    "print(model.hidden2.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Setting biases to all zeros\n",
    "model.hidden1.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get some data\n",
    "dataiter = iter(trainloader)\n",
    "images, label = dataiter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
